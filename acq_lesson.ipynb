{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6639b752-7b82-4831-a976-a06576eea54c",
   "metadata": {},
   "source": [
    "# Web Scraping Goals:\n",
    " - Find out how to grab some stuff out of a web page that might be useful for us\n",
    " - Find out how to do that more than once\n",
    " - Find out how to identify that stuff\n",
    " - Maybe learn a little more about HTML along the way\n",
    " - Put all that together to make an acquisition script (just like before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092afe0d",
   "metadata": {},
   "source": [
    "# Intro to Web Scraping\n",
    "- Use `requests` to download the HTML\n",
    "- Use `BeautifulSoup` to parse that HTML to get the thing(s) you need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ab8d2",
   "metadata": {},
   "source": [
    "## Process\n",
    "- Step 1: use the `request` library to make an HTTP request across the web\n",
    "- Step 2: use the `reponse.text` property on the `response` object to get the text of the HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32ffeca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38b133db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a url just like we did previously\n",
    "url = 'https://site-to-scrape.glitch.me'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfe099f-5b84-4741-880f-9a93ce6b6038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to grab the json() from the page like with API content will \n",
    "# unfortunately break if its made for humans:\n",
    "# get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4f25ffe-6c75-4fe9-ac4e-586d3626891a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html lang=\"en\">\\n  <head>\\n    <title>Site to Scrape!</title>\\n    <meta charset=\"utf-8\">\\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n    \\n    <!-- import the webpage\\'s stylesheet -->\\n    <link rel=\"stylesheet\" href=\"/style.css\">\\n    \\n    <!-- import the webpage\\'s javascript file -->\\n    <script src=\"/script.js\" defer></script>\\n  </head>  \\n  <body>\\n    <header>\\n      <h1>This is the header!</h1>\\n      <hr>\\n    </header>\\n    \\n    <main>\\n      <div>\\n        <h1 class=\"first\">\\n        This is the main\\n        </h1>\\n        <h2>\\n          This is an h2 of main\\n        </h2>\\n        <h3>\\n          H3 inside of first div inside of main\\n        </h3>\\n      </div>\\n      <div>\\n        <h3 class=\"first\">\\n          H3 inside of second div inside of main.\\n        </h3>\\n        <p>\\n          Here\\'s some text content for us to scrape! \\xf0\\x9f\\x91\\xbd\\n        </p>\\n        <p>\\n          Here\\'s another paragraph of content! \\xe2\\x98\\xa0\\xef\\xb8\\x8f\\n        </p>\\n        <a href=\"https://github.com/ryanorsinger\">Click here to visit my portfolio</a>       \\n      </div>\\n    </main>\\n\\n    <footer>\\n      <h1>This is the footer</h1>\\n      <img src=\"https://traffic-analytics.glitch.me/counter.png?fallback=MY_WEBSITE&color=black\" alt=\"\" style=\"vertical-align: bottom;\" aria-hidden=\"true\">\\n    </footer>\\n\\n  </body>\\n</html>\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab the text from our url\n",
    "# this gives us all the raw text that makes up the code of the \n",
    "# static site\n",
    "get(url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb3a9857-aca7-4adc-a589-5bcb3967136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's utilize beautiful soup to add to our response content:\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d54165e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll keep this url in our pocket for later\n",
    "url2 = 'https://web-scraping-demo.zgulde.net/news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95e54cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a soup:\n",
    "# recipe:\n",
    "# call BeautifulSoup on the content of our response\n",
    "soup = BeautifulSoup(get(url).content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85cbe785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "<title>Site to Scrape!</title>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
       "<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
       "<!-- import the webpage's stylesheet -->\n",
       "<link href=\"/style.css\" rel=\"stylesheet\"/>\n",
       "<!-- import the webpage's javascript file -->\n",
       "<script defer=\"\" src=\"/script.js\"></script>\n",
       "</head>\n",
       "<body>\n",
       "<header>\n",
       "<h1>This is the header!</h1>\n",
       "<hr/>\n",
       "</header>\n",
       "<main>\n",
       "<div>\n",
       "<h1 class=\"first\">\n",
       "        This is the main\n",
       "        </h1>\n",
       "<h2>\n",
       "          This is an h2 of main\n",
       "        </h2>\n",
       "<h3>\n",
       "          H3 inside of first div inside of main\n",
       "        </h3>\n",
       "</div>\n",
       "<div>\n",
       "<h3 class=\"first\">\n",
       "          H3 inside of second div inside of main.\n",
       "        </h3>\n",
       "<p>\n",
       "          Here's some text content for us to scrape! üëΩ\n",
       "        </p>\n",
       "<p>\n",
       "          Here's another paragraph of content! ‚ò†Ô∏è\n",
       "        </p>\n",
       "<a href=\"https://github.com/ryanorsinger\">Click here to visit my portfolio</a>\n",
       "</div>\n",
       "</main>\n",
       "<footer>\n",
       "<h1>This is the footer</h1>\n",
       "<img alt=\"\" aria-hidden=\"true\" src=\"https://traffic-analytics.glitch.me/counter.png?fallback=MY_WEBSITE&amp;color=black\" style=\"vertical-align: bottom;\"/>\n",
       "</footer>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we look at soup, its of the same structure as the text, but a little cleaner\n",
    "# and furthermore, its a new object -- a BeautifulSoup object\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27fd8c2-bb8e-4287-b839-1220329fae9e",
   "metadata": {},
   "source": [
    " - Begin with the End in Mind!\n",
    " - Figure out what you want to grab from a web page\n",
    " - figure out where it lives\n",
    " - figure out how many you want to grab (if theres more than one)\n",
    " - learn how to reference it ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e3268cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tag>\n",
    "# some stuff\n",
    "# <\\tag>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f910a5f1-40a1-40a5-a4e4-b24d9ae5f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# things we can do with soup:\n",
    "# reference elements directly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9f9376-17b9-46bb-99fe-4ba32fe4c1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b021ef34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "<title>Site to Scrape!</title>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
       "<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
       "<!-- import the webpage's stylesheet -->\n",
       "<link href=\"/style.css\" rel=\"stylesheet\"/>\n",
       "<!-- import the webpage's javascript file -->\n",
       "<script defer=\"\" src=\"/script.js\"></script>\n",
       "</head>\n",
       "<body>\n",
       "<header>\n",
       "<h1>This is the header!</h1>\n",
       "<hr/>\n",
       "</header>\n",
       "<main>\n",
       "<div>\n",
       "<h1 class=\"first\">\n",
       "        This is the main\n",
       "        </h1>\n",
       "<h2>\n",
       "          This is an h2 of main\n",
       "        </h2>\n",
       "<h3>\n",
       "          H3 inside of first div inside of main\n",
       "        </h3>\n",
       "</div>\n",
       "<div>\n",
       "<h3 class=\"first\">\n",
       "          H3 inside of second div inside of main.\n",
       "        </h3>\n",
       "<p>\n",
       "          Here's some text content for us to scrape! üëΩ\n",
       "        </p>\n",
       "<p>\n",
       "          Here's another paragraph of content! ‚ò†Ô∏è\n",
       "        </p>\n",
       "<a href=\"https://github.com/ryanorsinger\">Click here to visit my portfolio</a>\n",
       "</div>\n",
       "</main>\n",
       "<footer>\n",
       "<h1>This is the footer</h1>\n",
       "<img alt=\"\" aria-hidden=\"true\" src=\"https://traffic-analytics.glitch.me/counter.png?fallback=MY_WEBSITE&amp;color=black\" style=\"vertical-align: bottom;\"/>\n",
       "</footer>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1e97766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>\n",
       "          Here's some text content for us to scrape! üëΩ\n",
       "        </p>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I can reference tags with dot notation, but it seems to present \n",
    "# issues when there's more than one thing that I want.\n",
    "# what do?\n",
    "soup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "361a4268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>\n",
       "          Here's some text content for us to scrape! üëΩ\n",
       "        </p>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find:\n",
    "# think about find as \"find first\"\n",
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9e8bdd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>\n",
       "          Here's another paragraph of content! ‚ò†Ô∏è\n",
       "        </p>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# think about find_all as \"find all elements\"\n",
    "# its not technically a list but you will interact with it\n",
    "# in the same manner: [index]\n",
    "soup.find_all('p')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24782118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's another paragraph of content! ‚ò†Ô∏è\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we want to grab the content from each thing:\n",
    "# use .text to remove the html tags\n",
    "# use .strip() string method to remove the extra whitespace\n",
    "# use regex for anything else idk lol\n",
    "soup.find_all('p')[1].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "286a1e0d-127e-49b9-9edf-7695b8e2b9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the text content of our tag is already a string\n",
    "type(soup.find_all('p')[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3800259e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "is\n",
      "some\text\n"
     ]
    }
   ],
   "source": [
    "# remember escape keys for whitespace as we parse this stuff:\n",
    "print('here\\nis\\nsome\\text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "717508a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select is also a really useful one:\n",
    "# select will grab all css elements in a page:\n",
    "# equivalents: select_one is like find\n",
    "# select is like find_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1024062b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.select('h1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86367a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all('h1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e367c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the header!', 'This is the main', 'This is the footer']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use list comprehension to grab all the content that \n",
    "# I wanted from the h1 header tag:\n",
    "# translation:\n",
    "# the thing's text stripped of whitespace\n",
    "# for every element\n",
    "# that results from the soup.select() call\n",
    "# on my h1 named tag\n",
    "[thing.text.strip() for thing in soup.select('h1')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42e24d7-465c-43f3-bcaf-205b7fda1fa1",
   "metadata": {},
   "source": [
    "# Let's build on this:\n",
    " - Let's build a new task for ourselves:\n",
    " - Examine a new url\n",
    " - Figure out what we want to grab from it\n",
    " - Figure out how to grab it\n",
    " - Figure out how to do it programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dd467cdd-8ba8-41b0-87f2-8adfc6d72931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://web-scraping-demo.zgulde.net/news'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9ed29ce7-ae0e-4d5c-a25c-c5c0d2ea20f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's grab content from url2:\n",
    "# use get :\n",
    "response = get(url2).content\n",
    "# use soup: \n",
    "soup2 = BeautifulSoup(response, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "23b20ea0-f286-4aed-81ae-13542f0752d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup2.find_all('div'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c55d1c3-1ee9-4169-bf63-940177de2b53",
   "metadata": {},
   "source": [
    "We only have 12 articles here, so div may not be specific enough for our needs in this case\n",
    "\n",
    "let's go deeper!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88fccb7b-3faf-49ec-86b8-25fa581438d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup2.select('div'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "731bc12d-db75-4e56-8043-c6055c61c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last tactic here doesnt seem to be drilling down far enough:\n",
    "# [thing.text.strip() for thing in soup2.select('div')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e441380d-72e8-4ded-b17b-2d39ea9d2ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we want to reference the class out of here specifically:\n",
    "# classes can be referenced with dot notation\n",
    "# find_all does not play with the css as well as select:\n",
    "# this does not break but it gives us an empty set\n",
    "soup2.find_all('div.grid.grid-cols-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "35b7f59f-7ada-4581-bf63-819aec1d646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = soup2.select('div.grid.grid-cols-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4911982e-65db-4d4d-9bca-3e7ca8aacdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ten off choice'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0].h2.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "098e7c8f-1937-492e-a35e-7e4058d55310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ten off choice'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0].find('h2').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d62cbd29-1403-4c28-b50a-84c5fdfccf03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"grid grid-cols-4 gap-x-4 border rounded pr-3 bg-green-50 hover:shadow-lg transition duration-500\">\n",
       "<img src=\"/static/placeholder.png\"/>\n",
       "<div class=\"col-span-3 space-y-3 py-3\">\n",
       "<h2 class=\"text-2xl text-green-900\">ten off choice</h2>\n",
       "<div class=\"grid grid-cols-2 italic\">\n",
       "<p> 1971-08-07 </p>\n",
       "<p class=\"text-right\">By Cynthia Gutierrez </p>\n",
       "</div>\n",
       "<p>Worker who develop dog series big trouble. Structure glass rule give the movie. Direction movie along seat resource.\n",
       "Agent attention discussion very create mother part. Hit world model student. Discussion type citizen believe.</p>\n",
       "</div>\n",
       "</div>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ffbf99ab-1ed0-4ff3-bf82-3b9b8b4c1c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I found a way to reference the articles in the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5b44d150-4eaa-416f-a42a-1a5e3292ec81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p> 1971-08-07 </p>,\n",
       " <p class=\"text-right\">By Cynthia Gutierrez </p>,\n",
       " <p>Worker who develop dog series big trouble. Structure glass rule give the movie. Direction movie along seat resource.\n",
       " Agent attention discussion very create mother part. Hit world model student. Discussion type citizen believe.</p>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0].select('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dacfa70e-f0e9-49b1-acac-4c09e3fb3c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1971-08-07',\n",
       " 'By Cynthia Gutierrez',\n",
       " 'Worker who develop dog series big trouble. Structure glass rule give the movie. Direction movie along seat resource.\\nAgent attention discussion very create mother part. Hit world model student. Discussion type citizen believe.']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[thing.text.strip() for thing in articles[0].find_all('p')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b320f35e-d421-406f-ad2c-374b32acbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_content(some_article):\n",
    "    '''\n",
    "    grab the content out of the beautiful soup object\n",
    "    for each article in our overall set of articles\n",
    "    '''\n",
    "    output = {}\n",
    "    output['headline'] = some_article.find('h2').text.strip()\n",
    "    output['date'], output['author'], output['content'] = \\\n",
    "    [thing.text.strip() for thing in some_article.find_all('p')]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "440bf8df-8919-45db-9289-35262460e786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headline': 'ten off choice',\n",
       " 'date': '1971-08-07',\n",
       " 'author': 'By Cynthia Gutierrez',\n",
       " 'content': 'Worker who develop dog series big trouble. Structure glass rule give the movie. Direction movie along seat resource.\\nAgent attention discussion very create mother part. Hit world model student. Discussion type citizen believe.'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_article_content(articles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "614d4fe7-e340-49a9-86cd-494e045ce93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'headline': 'ten off choice',\n",
       "  'date': '1971-08-07',\n",
       "  'author': 'By Cynthia Gutierrez',\n",
       "  'content': 'Worker who develop dog series big trouble. Structure glass rule give the movie. Direction movie along seat resource.\\nAgent attention discussion very create mother part. Hit world model student. Discussion type citizen believe.'},\n",
       " {'headline': 'car value close',\n",
       "  'date': '1985-05-30',\n",
       "  'author': 'By Krystal Hampton',\n",
       "  'content': 'Record source bring away price. Moment help million responsibility eye talk himself. Who TV by.\\nTrial area lay rich later price and force. Picture change understand anyone standard.'},\n",
       " {'headline': 'physical accept town',\n",
       "  'date': '1977-06-27',\n",
       "  'author': 'By James Gonzalez',\n",
       "  'content': 'Activity television find building. Tree term upon. Visit place manager message hit.\\nLikely thousand station occur. Administration bring amount field guess care hard. Inside leg early we teacher policy.'},\n",
       " {'headline': 'future note cold',\n",
       "  'date': '1998-10-13',\n",
       "  'author': 'By Richard Cook',\n",
       "  'content': 'Professional capital line. Scientist hold line sit. Example number trade might away represent man.\\nLook man body particularly agree prove dream statement. Story military image analysis set difficult into.'},\n",
       " {'headline': 'Mr product relate',\n",
       "  'date': '1986-12-11',\n",
       "  'author': 'By Jennifer Frost',\n",
       "  'content': 'Growth strong she deep make. Care low else knowledge. So ready not soldier.\\nVarious whether street father remain. List economy however. Great prove treatment begin loss particularly report investment.'},\n",
       " {'headline': 'many base blue',\n",
       "  'date': '1989-12-03',\n",
       "  'author': 'By James Joseph',\n",
       "  'content': 'I environment watch. Visit only man live central major think.\\nSuffer relate really industry. What general be rate. Together official business foreign alone west clear. Agency treatment late system those.'},\n",
       " {'headline': 'perform push exist',\n",
       "  'date': '1979-10-31',\n",
       "  'author': 'By Regina Rhodes',\n",
       "  'content': 'Focus allow relationship much. Use to really.\\nNearly college moment society.'},\n",
       " {'headline': 'maintain each present',\n",
       "  'date': '2017-12-10',\n",
       "  'author': 'By Charles Harris',\n",
       "  'content': 'Over foot among role. Throughout end next site data market may. Pull back institution lawyer.\\nSuddenly company the cold marriage. Left garden establish understand hospital resource store.'},\n",
       " {'headline': 'whose network home',\n",
       "  'date': '1970-02-10',\n",
       "  'author': 'By David Howell',\n",
       "  'content': 'Attack ground he even technology. Another two travel kitchen bit again. Between skin win Mr into partner relate.\\nOthers sell argue even. Science card bank.'},\n",
       " {'headline': 'hand indicate election',\n",
       "  'date': '2012-01-13',\n",
       "  'author': 'By Heidi Castillo',\n",
       "  'content': 'Those heart produce yourself old goal fire cell. Stage shoulder message certainly couple. Later physical anyone expect third Congress.\\nOk concern turn long energy hotel practice. Public individual pretty. Artist show room picture compare still let.'},\n",
       " {'headline': 'action truth feeling',\n",
       "  'date': '1977-10-31',\n",
       "  'author': 'By Joseph Gill',\n",
       "  'content': 'Federal risk tend. Let study bring everyone enough. Share must also cover.\\nCongress identify country. Two many sound man. Network leave realize.'},\n",
       " {'headline': 'set national college',\n",
       "  'date': '1981-06-12',\n",
       "  'author': 'By Janice Moyer',\n",
       "  'content': 'Including why then himself but. Foot quite themselves how few up why.\\nAnalysis consider day cover though. Admit national lot play. Effect poor tax high.'}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the get_article_content for every \n",
    "# article in the list of articles,\n",
    "# resulting in a list of dictionaries\n",
    "[get_article_content(article) for article in articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "efd9d99d-9190-4ee9-b416-3fc4c52fd8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "96546e24-9fbf-46ed-8063-08dd43045273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_articles(url):\n",
    "    '''\n",
    "    Given a url with the expected strucure,\n",
    "    acquire_articles will pull the contents\n",
    "    of the web page and return a dataframe of \n",
    "    all of the articles inside the page\n",
    "    '''\n",
    "    soup = BeautifulSoup(get(url).content, 'html.parser')\n",
    "    articles = soup.select('div.grid.grid-cols-4')\n",
    "    return pd.DataFrame([get_article_content(article) for article in articles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e38a1fd9-eb5c-4dab-acda-02ae27518418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>child expert coach</td>\n",
       "      <td>2009-06-19</td>\n",
       "      <td>By Desiree Hicks MD</td>\n",
       "      <td>Unit family scientist send most source growth....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fact message just</td>\n",
       "      <td>1997-02-23</td>\n",
       "      <td>By Jennifer Pacheco MD</td>\n",
       "      <td>American society inside theory. Risk worker la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>responsibility interest Mr</td>\n",
       "      <td>1972-06-12</td>\n",
       "      <td>By Jeremy Blake</td>\n",
       "      <td>Beautiful line fire then relationship career h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>family lay key</td>\n",
       "      <td>1998-12-25</td>\n",
       "      <td>By Trevor Spencer</td>\n",
       "      <td>Cup instead yeah believe local. Space soon whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>practice pass watch</td>\n",
       "      <td>1971-12-04</td>\n",
       "      <td>By Craig Brown</td>\n",
       "      <td>Outside figure international board gun.\\nMemor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>court hundred beyond</td>\n",
       "      <td>1992-12-30</td>\n",
       "      <td>By Samantha Curtis</td>\n",
       "      <td>Girl agency boy realize notice player hit. Att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>while choice a</td>\n",
       "      <td>2021-04-04</td>\n",
       "      <td>By Andrew Obrien</td>\n",
       "      <td>Discuss event rate outside my determine at. Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>inside these fight</td>\n",
       "      <td>2006-09-30</td>\n",
       "      <td>By Victoria Murillo</td>\n",
       "      <td>Interview throughout ready direction get.\\nDir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>skin safe structure</td>\n",
       "      <td>1975-03-08</td>\n",
       "      <td>By Elizabeth Owens</td>\n",
       "      <td>Not opportunity feeling similar still recent w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>from pull mission</td>\n",
       "      <td>2009-08-24</td>\n",
       "      <td>By Kimberly Sanders</td>\n",
       "      <td>High level how be peace. Clearly write suffer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>require American say</td>\n",
       "      <td>2009-12-06</td>\n",
       "      <td>By Raymond Davidson</td>\n",
       "      <td>Provide party crime summer. Others read age la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>understand politics even</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>By Austin Ross</td>\n",
       "      <td>Social top same hair easy reach production. Te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      headline        date                  author  \\\n",
       "0           child expert coach  2009-06-19     By Desiree Hicks MD   \n",
       "1            fact message just  1997-02-23  By Jennifer Pacheco MD   \n",
       "2   responsibility interest Mr  1972-06-12         By Jeremy Blake   \n",
       "3               family lay key  1998-12-25       By Trevor Spencer   \n",
       "4          practice pass watch  1971-12-04          By Craig Brown   \n",
       "5         court hundred beyond  1992-12-30      By Samantha Curtis   \n",
       "6               while choice a  2021-04-04        By Andrew Obrien   \n",
       "7           inside these fight  2006-09-30     By Victoria Murillo   \n",
       "8          skin safe structure  1975-03-08      By Elizabeth Owens   \n",
       "9            from pull mission  2009-08-24     By Kimberly Sanders   \n",
       "10        require American say  2009-12-06     By Raymond Davidson   \n",
       "11    understand politics even  2021-11-27          By Austin Ross   \n",
       "\n",
       "                                              content  \n",
       "0   Unit family scientist send most source growth....  \n",
       "1   American society inside theory. Risk worker la...  \n",
       "2   Beautiful line fire then relationship career h...  \n",
       "3   Cup instead yeah believe local. Space soon whi...  \n",
       "4   Outside figure international board gun.\\nMemor...  \n",
       "5   Girl agency boy realize notice player hit. Att...  \n",
       "6   Discuss event rate outside my determine at. Me...  \n",
       "7   Interview throughout ready direction get.\\nDir...  \n",
       "8   Not opportunity feeling similar still recent w...  \n",
       "9   High level how be peace. Clearly write suffer ...  \n",
       "10  Provide party crime summer. Others read age la...  \n",
       "11  Social top same hair easy reach production. Te...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it out:\n",
    "acquire_articles(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97faca4b-9a10-4553-9b76-778a3259b6ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
